{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27d85db5-407f-4738-93df-93a3e2bb95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor,create_react_agent,Tool,create_tool_calling_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import Dict,List\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import json\n",
    "from langchain_core.prompts import PromptTemplate,ChatPromptTemplate\n",
    "\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chains import LLMChain\n",
    "from concurrent.futures.thread import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "import time\n",
    "import json\n",
    "from pydantic import BaseModel,Field\n",
    "from typing import List,Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1151fe71-4e0f-467a-a921-0b84bbffa919",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI(\n",
    "    # model=\"mistralai/mistral-nemo-instruct-2407\",\n",
    "    # model=\"qwen/qwen3-4b-thinking-2507\",\n",
    "    model=\"hermes-3-llama-3.2-3b\",\n",
    "    base_url=\"http://127.0.0.1:1239/v1/\",\n",
    "    api_key=\"dewfe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a0468dd-3f5d-49e7-af42-b49910f94636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"content\": {\"additionalProperties\": true, \"description\": \"response of llm\", \"title\": \"Content\", \"type\": \"object\"}}, \"required\": [\"content\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "class parser(BaseModel):\n",
    "    content:dict=Field(description=\"response of llm\")\n",
    "    \n",
    "oup_parser=PydanticOutputParser(pydantic_object=parser)\n",
    "\n",
    "print(oup_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1723aaf0-089f-443b-958b-af74719d714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "# Create the main window\n",
    "def helper():\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Hello Tkinter\")\n",
    "    \n",
    "    # Add a label widget\n",
    "    label = tk.Label(root, text=\"Hello, World!\")\n",
    "    label.pack()\n",
    "    \n",
    "    # Run the application\n",
    "    root.mainloop()\n",
    "\n",
    "helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7af09d59-255c-427e-a38c-7ca3c67ea013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:{'prompt': 'Generate a poll based on the context: Python Developers Hub generate poll', 'max_input_length': 1024, 'stop': ['yes', 'no', 'maybe', 'definitely not', 'probably', 'possibly', 'likely', 'unlikely'], 'temperature': 0.5, 'top_k': -1, 'n': 10}\n",
      "TIME TAKEN:58.38736176490784\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import tool\n",
    "\n",
    "# th_pl_exec=ThreadPoolExecutor(max_workers=3)\n",
    "\n",
    "@tool\n",
    "def pollGenerator(context: str) -> dict:\n",
    "    \"\"\"This tool generates a poll for the room to increase engagement.\n",
    "    Return a dictionary \n",
    "    \"\"\"\n",
    "\n",
    "    template=ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"\"\"\n",
    "        you are a poll generator \n",
    "        based on context:{context} generate poll\n",
    "\n",
    "        output in format:{format}\n",
    "        \"\"\")   \n",
    "    ])\n",
    "\n",
    "    llm_struct=llm.with_structured_output(parser)\n",
    "    chain=template|llm_struct\n",
    "    result=chain.invoke({\"context\":context,\"format\":oup_parser.get_format_instructions()}).content\n",
    "    print(f\"Result:{result}\")\n",
    "    #trigger tkinter\n",
    "    helper()\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "def create_room_agent():\n",
    "    tools = [pollGenerator]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are an expert assistant that makes chat rooms more interactive and viral.\"),\n",
    "        (\"human\", \n",
    "        \"\"\"Room Name: {room_name}\n",
    "        Room Description: {room_desc}\n",
    "        Recent Chats: {chats}\n",
    "\n",
    "        based on provided tools call the correct one:\n",
    "        {tool_names}\n",
    "\n",
    "        give tool output also\n",
    "        Task: {input}\n",
    "        Reasoning:{agent_scratchpad}\n",
    "\n",
    "        \n",
    "        \"\"\")\n",
    "    ])\n",
    "\n",
    "    # ✅ Correct agent constructor\n",
    "    agent = create_tool_calling_agent(llm, tools, prompt,)\n",
    "\n",
    "    # ✅ Executor to run agent\n",
    "    executor = AgentExecutor(agent=agent, tools=tools,max_iterations=1)#,verbose=True)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def main():\n",
    "    agent_executor = create_room_agent()\n",
    "    \n",
    "    room_data = {\n",
    "        \"room_name\": \"Python Developers Hub\",\n",
    "        \"room_desc\": \"A community for Python enthusiasts to share code and learn\",\n",
    "        \"chats\": \"User1: Anyone know good Python resources?\\nUser2: I'm working on a Django project\",\n",
    "        \"input\": \"Generate a poll for this room\",\n",
    "        \"tool_names\":[\"pollGenerator\"]\n",
    "    }\n",
    "\n",
    "    result = agent_executor.invoke(room_data)\n",
    "    # print(\"\\n✅ AGENT RESULT:\", result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    time_start=time.time()\n",
    "    main()\n",
    "    print(f\"TIME TAKEN:{time.time()-time_start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b580b1-f156-4c9f-bb1b-3a918e64f48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
